{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Stable Diffusion Dream Script This is a fork of CompVis/stable-diffusion , the open source text-to-image generator. It provides a streamlined process with various new features and options to aid the image generation process. It runs on Windows, Mac and Linux machines, and runs on GPU cards with as little as 4 GB or RAM. Note: This fork is rapidly evolving. Please use the Issues tab to report bugs and make feature requests. Be sure to use the provided templates. They will help aid diagnose issues faster. Installation # This fork is supported across multiple platforms. You can find individual installation instructions below. Linux Windows Macintosh Hardware Requirements # System # You wil need one of the following: An NVIDIA-based graphics card with 4 GB or more VRAM memory. An Apple computer with an M1 chip. Memory # At least 12 GB Main Memory RAM. Disk # At least 6 GB of free disk space for the machine learning model, Python, and all its dependencies. Note # If you are have a Nvidia 10xx series card (e.g. the 1080ti), please run the dream script in full-precision mode as shown below. Similarly, specify full-precision mode on Apple M1 hardware. To run in full-precision mode, start dream.py with the --full_precision flag: ( ldm ) ~/stable-diffusion$ python scripts/dream.py --full_precision Features # Major Features # Interactive Command Line Interface Image To Image Inpainting Support GFPGAN and Real-ESRGAN Support Seamless Tiling Google Colab Web Server Reading Prompts From File Shortcut: Reusing Seeds Weighted Prompts Variations Personalizing Text-to-Image Generation Simplified API for text to image generation Other Features # Creating Transparent Regions for Inpainting Preload Models Latest Changes # v1.14 (11 September 2022) # Memory optimizations for small-RAM cards. 512x512 now possible on 4 GB GPUs. Full support for Apple hardware with M1 or M2 chips. Add \"seamless mode\" for circular tiling of image. Generates beautiful effects. ( prixt ). Inpainting support. Improved web server GUI. Lots of code and documentation cleanups. v1.13 (3 September 2022 # Support image variations (see VARIATIONS ( Kevin Gibbons and many contributors and reviewers) Supports a Google Colab notebook for a standalone server running on Google hardware Arturo Mendivil WebUI supports GFPGAN/ESRGAN facial reconstruction and upscaling Kevin Gibbons WebUI supports incremental display of in-progress images during generation Kevin Gibbons A new configuration file scheme that allows new models (including upcoming stable-diffusion-v1.5) to be added without altering the code. ( David Wager ) Can specify --grid on dream.py command line as the default. Miscellaneous internal bug and stability fixes. Works on M1 Apple hardware. Multiple bug fixes. For older changelogs, please visit the CHANGELOG . Troubleshooting # Please check out our Q&A to get solutions for common installation problems and other issues. Contributing # Anyone who wishes to contribute to this project, whether documentation, features, bug fixes, code cleanup, testing, or code reviews, is very much encouraged to do so. If you are unfamiliar with how to contribute to GitHub projects, here is a Getting Started Guide . A full set of contribution guidelines, along with templates, are in progress, but for now the most important thing is to make your pull request against the \"development\" branch , and not against \"main\". This will help keep public breakage to a minimum and will allow you to propose more radical changes. Contributors # This fork is a combined effort of various people from across the world. Check out the list of all these amazing people . We thank them for their time, hard work and effort. Support # For support, please use this repository's GitHub Issues tracking service. Feel free to send me an email if you use and like the script. Original portions of the software are Copyright \u00a9 2020 Lincoln D. Stein Further Reading # Please see the original README for more information on this software and underlying algorithm, located in the file README-CompViz.md .","title":"Home"},{"location":"#installation","text":"This fork is supported across multiple platforms. You can find individual installation instructions below. Linux Windows Macintosh","title":"Installation"},{"location":"#hardware-requirements","text":"","title":"Hardware Requirements"},{"location":"#system","text":"You wil need one of the following: An NVIDIA-based graphics card with 4 GB or more VRAM memory. An Apple computer with an M1 chip.","title":"System"},{"location":"#memory","text":"At least 12 GB Main Memory RAM.","title":"Memory"},{"location":"#disk","text":"At least 6 GB of free disk space for the machine learning model, Python, and all its dependencies.","title":"Disk"},{"location":"#note","text":"If you are have a Nvidia 10xx series card (e.g. the 1080ti), please run the dream script in full-precision mode as shown below. Similarly, specify full-precision mode on Apple M1 hardware. To run in full-precision mode, start dream.py with the --full_precision flag: ( ldm ) ~/stable-diffusion$ python scripts/dream.py --full_precision","title":"Note"},{"location":"#features","text":"","title":"Features"},{"location":"#major-features","text":"Interactive Command Line Interface Image To Image Inpainting Support GFPGAN and Real-ESRGAN Support Seamless Tiling Google Colab Web Server Reading Prompts From File Shortcut: Reusing Seeds Weighted Prompts Variations Personalizing Text-to-Image Generation Simplified API for text to image generation","title":"Major Features"},{"location":"#other-features","text":"Creating Transparent Regions for Inpainting Preload Models","title":"Other Features"},{"location":"#latest-changes","text":"","title":"Latest Changes"},{"location":"#v114-11-september-2022","text":"Memory optimizations for small-RAM cards. 512x512 now possible on 4 GB GPUs. Full support for Apple hardware with M1 or M2 chips. Add \"seamless mode\" for circular tiling of image. Generates beautiful effects. ( prixt ). Inpainting support. Improved web server GUI. Lots of code and documentation cleanups.","title":"v1.14 (11 September 2022)"},{"location":"#v113-3-september-2022","text":"Support image variations (see VARIATIONS ( Kevin Gibbons and many contributors and reviewers) Supports a Google Colab notebook for a standalone server running on Google hardware Arturo Mendivil WebUI supports GFPGAN/ESRGAN facial reconstruction and upscaling Kevin Gibbons WebUI supports incremental display of in-progress images during generation Kevin Gibbons A new configuration file scheme that allows new models (including upcoming stable-diffusion-v1.5) to be added without altering the code. ( David Wager ) Can specify --grid on dream.py command line as the default. Miscellaneous internal bug and stability fixes. Works on M1 Apple hardware. Multiple bug fixes. For older changelogs, please visit the CHANGELOG .","title":"v1.13 (3 September 2022"},{"location":"#troubleshooting","text":"Please check out our Q&A to get solutions for common installation problems and other issues.","title":"Troubleshooting"},{"location":"#contributing","text":"Anyone who wishes to contribute to this project, whether documentation, features, bug fixes, code cleanup, testing, or code reviews, is very much encouraged to do so. If you are unfamiliar with how to contribute to GitHub projects, here is a Getting Started Guide . A full set of contribution guidelines, along with templates, are in progress, but for now the most important thing is to make your pull request against the \"development\" branch , and not against \"main\". This will help keep public breakage to a minimum and will allow you to propose more radical changes.","title":"Contributing"},{"location":"#contributors","text":"This fork is a combined effort of various people from across the world. Check out the list of all these amazing people . We thank them for their time, hard work and effort.","title":"Contributors"},{"location":"#support","text":"For support, please use this repository's GitHub Issues tracking service. Feel free to send me an email if you use and like the script. Original portions of the software are Copyright \u00a9 2020 Lincoln D. Stein","title":"Support"},{"location":"#further-reading","text":"Please see the original README for more information on this software and underlying algorithm, located in the file README-CompViz.md .","title":"Further Reading"},{"location":"features/CHANGELOG/","text":"v1.13 (in process) # Supports a Google Colab notebook for a standalone server running on Google hardware Arturo Mendivil WebUI supports GFPGAN/ESRGAN facial reconstruction and upscaling Kevin Gibbons WebUI supports incremental display of in-progress images during generation Kevin Gibbons Output directory can be specified on the dream> command line. The grid was displaying duplicated images when not enough images to fill the final row Muhammad Usama Can specify --grid on dream.py command line as the default. Miscellaneous internal bug and stability fixes. v1.12 (28 August 2022) # Improved file handling, including ability to read prompts from standard input. (kudos to Yunsaki The web server is now integrated with the dream.py script. Invoke by adding --web to the dream.py command arguments. Face restoration and upscaling via GFPGAN and Real-ESGAN are now automatically enabled if the GFPGAN directory is located as a sibling to Stable Diffusion. VRAM requirements are modestly reduced. Thanks to both Blessedcoolant and Oceanswave for their work on this. You can now swap samplers on the dream> command line. Blessedcoolant v1.11 (26 August 2022) # NEW FEATURE: Support upscaling and face enhancement using the GFPGAN module. (kudos to Oceanswave ) You now can specify a seed of -1 to use the previous image's seed, -2 to use the seed for the image generated before that, etc. Seed memory only extends back to the previous command, but will work on all images generated with the -n# switch. Variant generation support temporarily disabled pending more general solution. Created a feature branch named yunsaki-morphing-dream which adds experimental support for iteratively modifying the prompt and its parameters. Please see Pull Request #86 for a synopsis of how this works. Note that when this feature is eventually added to the main branch, it will may be modified significantly. v1.10 (25 August 2022) # A barebones but fully functional interactive web server for online generation of txt2img and img2img. v1.09 (24 August 2022) # A new -v option allows you to generate multiple variants of an initial image in img2img mode. (kudos to Oceanswave . See this discussion in the PR for examples and details on use ) Added ability to personalize text to image generation (kudos to Oceanswave and nicolai256 ) Enabled all of the samplers from k_diffusion v1.08 (24 August 2022) # Escape single quotes on the dream> command before trying to parse. This avoids parse errors. Removed instruction to get Python3.8 as first step in Windows install. Anaconda3 does it for you. Added bounds checks for numeric arguments that could cause crashes. Cleaned up the copyright and license agreement files. v1.07 (23 August 2022) # Image filenames will now never fill gaps in the sequence, but will be assigned the next higher name in the chosen directory. This ensures that the alphabetic and chronological sort orders are the same. v1.06 (23 August 2022) # Added weighted prompt support contributed by xraxra Example of using weighted prompts to tweak a demonic figure contributed by bmaltais v1.05 (22 August 2022 - after the drop) # Filenames now use the following formats: 000010.95183149.png -- Two files produced by the same command (e.g. -n2), 000010.26742632.png -- distinguished by a different seed. 000011.455191342.01.png -- Two files produced by the same command using 000011.455191342.02.png -- a batch size>1 (e.g. -b2). They have the same seed. 000011.4160627868.grid#1 -4.png -- a grid of four images (-g); the whole grid can be regenerated with the indicated key It should no longer be possible for one image to overwrite another You can use the \"cd\" and \"pwd\" commands at the dream> prompt to set and retrieve the path of the output directory. v1.04 (22 August 2022 - after the drop) # Updated README to reflect installation of the released weights. Suppressed very noisy and inconsequential warning when loading the frozen CLIP tokenizer. v1.03 (22 August 2022) # The original txt2img and img2img scripts from the CompViz repository have been moved into a subfolder named \"orig_scripts\", to reduce confusion. v1.02 (21 August 2022) # A copy of the prompt and all of its switches and options is now stored in the corresponding image in a tEXt metadata field named \"Dream\". You can read the prompt using scripts/images2prompt.py, or an image editor that allows you to explore the full metadata. Please run \"conda env update -f environment.yaml\" to load the k_lms dependencies!! v1.01 (21 August 2022) # added k_lms sampling. Please run \"conda env update -f environment.yaml\" to load the k_lms dependencies!! use half precision arithmetic by default, resulting in faster execution and lower memory requirements Pass argument --full_precision to dream.py to get slower but more accurate image generation","title":"Changelog"},{"location":"features/CHANGELOG/#v113-in-process","text":"Supports a Google Colab notebook for a standalone server running on Google hardware Arturo Mendivil WebUI supports GFPGAN/ESRGAN facial reconstruction and upscaling Kevin Gibbons WebUI supports incremental display of in-progress images during generation Kevin Gibbons Output directory can be specified on the dream> command line. The grid was displaying duplicated images when not enough images to fill the final row Muhammad Usama Can specify --grid on dream.py command line as the default. Miscellaneous internal bug and stability fixes.","title":"v1.13 (in process)"},{"location":"features/CHANGELOG/#v112-28-august-2022","text":"Improved file handling, including ability to read prompts from standard input. (kudos to Yunsaki The web server is now integrated with the dream.py script. Invoke by adding --web to the dream.py command arguments. Face restoration and upscaling via GFPGAN and Real-ESGAN are now automatically enabled if the GFPGAN directory is located as a sibling to Stable Diffusion. VRAM requirements are modestly reduced. Thanks to both Blessedcoolant and Oceanswave for their work on this. You can now swap samplers on the dream> command line. Blessedcoolant","title":"v1.12 (28 August 2022)"},{"location":"features/CHANGELOG/#v111-26-august-2022","text":"NEW FEATURE: Support upscaling and face enhancement using the GFPGAN module. (kudos to Oceanswave ) You now can specify a seed of -1 to use the previous image's seed, -2 to use the seed for the image generated before that, etc. Seed memory only extends back to the previous command, but will work on all images generated with the -n# switch. Variant generation support temporarily disabled pending more general solution. Created a feature branch named yunsaki-morphing-dream which adds experimental support for iteratively modifying the prompt and its parameters. Please see Pull Request #86 for a synopsis of how this works. Note that when this feature is eventually added to the main branch, it will may be modified significantly.","title":"v1.11 (26 August 2022)"},{"location":"features/CHANGELOG/#v110-25-august-2022","text":"A barebones but fully functional interactive web server for online generation of txt2img and img2img.","title":"v1.10 (25 August 2022)"},{"location":"features/CHANGELOG/#v109-24-august-2022","text":"A new -v option allows you to generate multiple variants of an initial image in img2img mode. (kudos to Oceanswave . See this discussion in the PR for examples and details on use ) Added ability to personalize text to image generation (kudos to Oceanswave and nicolai256 ) Enabled all of the samplers from k_diffusion","title":"v1.09 (24 August 2022)"},{"location":"features/CHANGELOG/#v108-24-august-2022","text":"Escape single quotes on the dream> command before trying to parse. This avoids parse errors. Removed instruction to get Python3.8 as first step in Windows install. Anaconda3 does it for you. Added bounds checks for numeric arguments that could cause crashes. Cleaned up the copyright and license agreement files.","title":"v1.08 (24 August 2022)"},{"location":"features/CHANGELOG/#v107-23-august-2022","text":"Image filenames will now never fill gaps in the sequence, but will be assigned the next higher name in the chosen directory. This ensures that the alphabetic and chronological sort orders are the same.","title":"v1.07 (23 August 2022)"},{"location":"features/CHANGELOG/#v106-23-august-2022","text":"Added weighted prompt support contributed by xraxra Example of using weighted prompts to tweak a demonic figure contributed by bmaltais","title":"v1.06 (23 August 2022)"},{"location":"features/CHANGELOG/#v105-22-august-2022-after-the-drop","text":"Filenames now use the following formats: 000010.95183149.png -- Two files produced by the same command (e.g. -n2), 000010.26742632.png -- distinguished by a different seed. 000011.455191342.01.png -- Two files produced by the same command using 000011.455191342.02.png -- a batch size>1 (e.g. -b2). They have the same seed. 000011.4160627868.grid#1 -4.png -- a grid of four images (-g); the whole grid can be regenerated with the indicated key It should no longer be possible for one image to overwrite another You can use the \"cd\" and \"pwd\" commands at the dream> prompt to set and retrieve the path of the output directory.","title":"v1.05 (22 August 2022 - after the drop)"},{"location":"features/CHANGELOG/#v104-22-august-2022-after-the-drop","text":"Updated README to reflect installation of the released weights. Suppressed very noisy and inconsequential warning when loading the frozen CLIP tokenizer.","title":"v1.04 (22 August 2022 - after the drop)"},{"location":"features/CHANGELOG/#v103-22-august-2022","text":"The original txt2img and img2img scripts from the CompViz repository have been moved into a subfolder named \"orig_scripts\", to reduce confusion.","title":"v1.03 (22 August 2022)"},{"location":"features/CHANGELOG/#v102-21-august-2022","text":"A copy of the prompt and all of its switches and options is now stored in the corresponding image in a tEXt metadata field named \"Dream\". You can read the prompt using scripts/images2prompt.py, or an image editor that allows you to explore the full metadata. Please run \"conda env update -f environment.yaml\" to load the k_lms dependencies!!","title":"v1.02 (21 August 2022)"},{"location":"features/CHANGELOG/#v101-21-august-2022","text":"added k_lms sampling. Please run \"conda env update -f environment.yaml\" to load the k_lms dependencies!! use half precision arithmetic by default, resulting in faster execution and lower memory requirements Pass argument --full_precision to dream.py to get slower but more accurate image generation","title":"v1.01 (21 August 2022)"}]}